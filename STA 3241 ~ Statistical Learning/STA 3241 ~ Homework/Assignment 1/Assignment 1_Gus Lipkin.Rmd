---
title: "Assignment 1"
author: "Gus Lipkin ~ glipkin6737@floridapoly.edu"
output:
  html_notebook: default
  pdf_document: default
---

# Problem 8
> This exercise relates to the `College` data set, which can be found in the file `College.csv` on the book website. It contains a number of variables for 777 different universities and colleges in the US. The variables are
>
> [ommitted for simplicity]
>
> Before reading the data into `R, it can be viewed in Excel or a text editor.

## 8a
> Use the `read.csv()` function to read the data into R. Call the loaded data `college.` Make sure that you have the directory set to the correct location for the data.

```{r}
college <- read.csv("College.csv")
```

# 8b
> Look at the data using the `View()` function. You should notice that the first column is just the name of each university. We donâ€™t really want R to treat this as data. However, it may be handy to have these names for later. Try the following commands:
>
> `rownames(college) <- college[, 1]`
>
> `View(college)`
>
> You should see that there is now a `row.names` column with the name of each university recorded. This means that R has given each row a name corresponding to the appropriate university. R will not try to perform calculations on the row names. However, we still need to eliminate the first column in the data where the names are stored. Try
>
> `college <- college[, -1]`
>
> `View(college)`
>
> Now you should see that the first data column is `Private.` Note that another column labeled `row.names` now appears before the `Private` column. However, this is not a data column but rather the name that R is giving to each row.

```{r}
# Commenting this out because it doesn't work with html notebooks
# View(college)
head(college)
# Using row names is outdated...
rownames(college) <- college[, 1]
# View(college)
head(college)
college <- college[, -1]
# View(college)
head(college)
```

## 8c
### 8c i
> Use the `summary()` function to produce a numerical summary of the variables in the data set.

```{r}
summary(college)
```

### 8c ii
> Use the `pairs()` function to produce a scatterplot matrix of the first ten columns or variables of the data. Recall that you can reference the first ten columns of a matrix `A` using `A[,1:10]`.

```{r}
# The first column is whether or not it is a private school (character) and isn't allowed by `pairs`
pairs(college[,2:11])
```

### 8c iii
> Use the `plot()` function to produce side-by-side boxplots of `Outstate` versus `Private`.

```{r}
college$Private <- as.factor(college$Private)
plot(college$Private, college$Outstate)
```

### 8c iv
> Create a new qualitative variable, called `Elite`, by binning the `Top10perc` variable. We are going to divide universities into two groups based on whether or not the proportion of students coming from the top $10\%$ of their high school classes exceeds $50\%$.
> `Elite <- rep("No", nrow(college))`
>
> `Elite[college$Top10perc > 50] <- "Yes"`
> 
> `Elite <- as.factor(Elite)`
> 
> `college <- data.frame(college, Elite)`
> Use the `summary()` function to see how many elite univer- sities there are. Now use the `plot()` function to produce side-by-side boxplots of `Outstate` versus `Elite`.

```{r}
# Here's the code they gave you, but it's super inefficient
# Elite <- rep("No", nrow(college))
# Elite[college$Top10perc > 50] <- "Yes"
# Elite <- as.factor(Elite)
# college <- data.frame(college, Elite)
college$Elite <- as.factor(ifelse(college$Top10perc > 50, "Yes", "No"))
summary(college$Elite)
plot(college$Elite, college$Outstate)
```

### 8c v
> Use the `hist()` function to produce some histograms with differing numbers of bins for a few of the quantitative vari- ables. You may find the command `par(mfrow = c(2, 2))` useful: it will divide the print window into four regions so that four plots can be made simultaneously. Modifying the arguments to this function will divide the screen in other ways.

```{r}
par(mfrow = c(2, 2))
hist(college$Apps, breaks = 5)
hist(college$Accept, breaks = 10)
hist(college$Enroll, breaks = 15)
hist(college$Top25perc, breaks = 25)
```

### 8c vi
> Continue exploring the data, and provide a brief summary of what you discover.

```{r}
college$AcceptRate <- college$Accept / college$Apps
acceptRate <- lm(Grad.Rate ~ AcceptRate, data = college)
acceptRate
summary(acceptRate)
```

People generally assume that schools with lower acceptance rates are more prestigious and more academically rigorous. I wanted to see if that is true. I created a metric for the acceptance rate: $\frac{\textrm{# accepted}}{\textrm{# apps}}$. I then performed a simple linear regression to see if the acceptance rate is a good predictor of the graduation rate. In theory, it is based on p-value, but not based on the R-squared.

## 9
> This exercise involves the `Auto` data set studied in the lab. Make sure that the missing values have been removed from the data.

```{r}
library(data.table)
library(tidyverse)
auto <- fread("Auto.csv")
# This checks for na values
sum(is.na(auto))
```

### 9a
> Which of the predictors are quantitative, and which are qualitative?

```{r}
# These are quantitative
colnames(select_if(auto, is.numeric))
# These are qualitative
colnames(select_if(auto, negate(is.numeric)))
```

### 9b
> What is the range of each quantitative predictor? You can answer this using the `range()` function.

```{r}
sapply(select_if(auto, is.numeric), range)
```

### 9c
> What is the mean and standard deviation of each quantitative predictor?

```{r}
sapply(select_if(auto, is.numeric), mean)
sapply(select_if(auto, is.numeric), sd)
```

### 9d
> Now remove the 10th through 85th observations. What is the range, mean, and standard deviation of each predictor in the subset of the data that remains?

```{r}
smallAuto <- auto[c(1:9, 85:nrow(auto)),]
summary(select_if(smallAuto, is.numeric))
```

### 9e
> Using the full data set, investigate the predictors graphically, using scatterplots or other tools of your choice. Create some plots highlighting the relationships among the predictors. Comment on your findings.

```{r}
SmartEDA::ExpReport(data = auto, op_file = "9e.html", Target = "mpg")
```

#### Exploratory Data Analysis Report for the Boston Dataset with a Focus on Gas Mileage

<div style = "display:block; clear:both; page-break-after:always;"></div>

```{r}
auto %>%
  ggplot() +
  geom_point(aes(x = displacement, y = as.numeric(horsepower)))
```

Wow. Displacement generally correlates with horsepower. Who could have predicted this?

```{r}
auto %>%
  ggplot() +
  geom_point(aes(x = weight, y = acceleration))
bigCarGoSlow <- lm(acceleration ~ weight + displacement, data = auto)
bigCarGoSlow
summary(bigCarGoSlow)
```
Horsepower should really be converted to numeric but I don't care. Big car go slow is probably correct unless it's an electric Hummer.

### 9f
> Suppose that we wish to predict gas mileage (`mpg`) on the basis of the other variables. Do your plots suggest that any of the other variables might be useful in predicting `mpg`? Justify your answer.

```{r}
auto$horsepower <- as.numeric(auto$horsepower)
mpg <- lm(mpg ~ cylinders + displacement + horsepower + weight + acceleration + 
            year + origin, data = auto)
mpg
summary(mpg)
```

Based on p-values, `displacement`, `weight`, `year`, and `origin` are all good predictors for `mpg`.

## 10
> This exercise involves the Boston housing data set.

### 10a
To begin, load in the `Boston` data set. The `Boston` data set is part of the `ISLR2` *library*.
>
> `library(ISLR2)`
> 
> Now the data set is contained in the object Boston. > Boston
> 
> Read about the data set:
> `?Boston`
> 
> How many rows are in this data set? How many columns? What do the rows and columns represent?

```{r}
library(ISLR2)
Boston
?Boston
```

### 10b
> Make some pairwise scatterplots of the predictors (columns) in this data set. Describe your findings.

```{r}
# Predict crime rate based on industry
Boston %>%
  ggplot() +
  geom_point(aes(x = indus, y = crim))
# Predict crime rate based on median home value
Boston %>%
  ggplot() +
  geom_point(aes(x = medv, y = crim))
```

Crime rates are low based on my selection criteria or maybe some places just have too much crime. I just looked at the next question. I hate this.

### 10c
> Are any of the predictors associated with per capita crime rate? If so, explain the relationship.

```{r}
crim <- lm(crim ~ zn + indus + chas + nox + rm + age + dis + rad + tax + ptratio + lstat + medv, data = Boston)
crim
summary(crim)
```

`zn`, `dis`, `rad`, and `medv` are good predictors. `zn` and `rad` correlate with an increase in crime while `dis` and `medv` correlate with a decrease in crime.

### 10d
> Do any of the census tracts of Boston appear to have particularly high crime rates? Tax rates? Pupil-teacher ratios? Comment on the range of each predictor.

```{r}
# DataExplorer::create_report(data = Boston,
#                             output_file = "10d.html",
#                             report_title = "Exploratory Data Analysis Report for 
#                             the Boston Dataset with a Focus on the Per Capita 
#                             Crime Rate",
#                             y = "crim")
# rmarkdown::pandoc_convert("10d.html", to = "pdf", from = "html", output = "10d.pdf")
```

<div style = "display:block; clear:both; page-break-after:always;"></div>

```{r}
par(mfrow = c(1, 3))
hist(Boston$crim[Boston$crim > 20], breaks = 20)
hist(Boston$tax, breaks = 20)
hist(Boston$ptratio, breaks = 20)
```

Some places have much higher predictor values than other places. It's probably the wealthy areas, I haven't looked.

### 10e
> How many of the census tracts in this data set bound the Charles river?

```{r}
nrow(Boston[Boston$chas == 1,])
```

### 10f
> What is the median pupil-teacher ratio among the towns in this data set?

```{r}
summary(Boston$ptratio)[3]
```

### 10g
> Which census tract of Boston has lowest median value of owner-occupied homes? What are the values of the other predictors for that census tract, and how do those values compare to the overall ranges for those predictors? Comment on your findings.

```{r}
Boston[Boston$medv == min(Boston$medv),]
```

`crim` and `lstat` are the only variables that are very different from each other. I'm not sure which tracts these are so I can't comment too much. But I do like that the tax is $666$.

### 10h
> In this data set, how many of the census tracts average more than seven rooms per dwelling? More than eight rooms per dwelling? Comment on the census tracts that average more than eight rooms per dwelling.

```{r}
# More than 7 rooms
nrow(Boston[Boston$rm > 7,])
# More than 8 rooms
nrow(Boston[Boston$rm > 8,])
summary(Boston[Boston$rm <= 8,])
summary(Boston[Boston$rm > 8,])
```

I'm just going to focus on the age bit because Boston is an historic city and area. I'm not surprised that larger homes are generally older than those that are not as large. This is probably due to old mansions which are abundant in the area. Also, median value is way higher for larger homes which is not at all surprising. I wish I knew what the tracts actually were so I could comment on that specific area rather than just the data.
