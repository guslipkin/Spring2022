---
title: "Assignment 5"
author: "Gus Lipkin ~ glipkin6737@floridapoly.edu"
output:
  html_notebook:
    toc: true
    toc_depth: 2
    toc_float: true
  pdf_document: default
---

> Please submit a html output of your R notebook and include summary statistics and explanation of the variables in the dataset. Also, please include an explanation of your model results. 

```{r}
library(data.table)
library(leaps)
```

# Problem 1
> Use the College dataset from ISLR2 library and use best subset selection, forward and backward selection methods to predict the number of applications received using the other variables. 

```{r}
dt <- data.table(ISLR2::College)
head(dt)
```

The `ISLR2::College` dataset contains "Statistics for a large number of US Colleges from the 1995 issue of US News and World Report." If you want to learn more, I suggest visiting [https://rdocumentation.org/packages/ISLR2/versions/1.3-1/topics/College](https://rdocumentation.org/packages/ISLR2/versions/1.3-1/topics/College).

## Summary Stats
```{r warning=FALSE}
summary(dt)
df <- dewey::ifelsedata(data.frame(round(cor(dt[, !c("Private")]), 3)), 
                        .85, "x >= y & x != 1", matchCols = FALSE)
rownames(df) <- colnames(df)
df
GGally::ggpairs(dt, mapping = ggplot2::aes(color = Private))
```

These are the summary statistics. There's nothing crazy about them in general. Maybe a few outliers. There aren't a ton of things that are correlated at a rate at or higher than $85\%$. It is all generally expected.

## Normal
```{r}
best_fit <- regsubsets(Apps ~ ., dt, nvmax = 17)
best_summary <- summary(best_fit)

data.table("BIC" = best_summary$bic,
           "Cp" = best_summary$cp,
           "r2" = best_summary$adjr2)[order(r2 * -1, BIC, Cp)]

par(mfrow = c(1,2))
plot(best_summary$cp, xlab = "number of features", ylab = "cp")
plot(best_fit, scale = "Cp")

par(mfrow = c(1, 2))
plot(best_summary$bic, xlab = "number of features", ylab = "bic")
plot(best_fit, scale = "bic")

normal <- as.formula("Apps ~ + Private + Accept + Enroll + Top10perc + Top25perc + Outstate + Room.Board + PhD + Expend + Grad.Rate")
```

## Forward
```{r}
best_fit <- regsubsets(Apps ~ ., dt, nvmax = 17, method = "forward")
best_summary <- summary(best_fit)

data.table("BIC" = best_summary$bic,
           "Cp" = best_summary$cp,
           "r2" = best_summary$adjr2)[order(r2 * -1, BIC, Cp)]

par(mfrow = c(1,2))
plot(best_summary$cp, xlab = "number of features", ylab = "cp")
plot(best_fit, scale = "Cp")

par(mfrow = c(1, 2))
plot(best_summary$bic, xlab = "number of features", ylab = "bic")
plot(best_fit, scale = "bic")

forward <- as.formula("Apps ~ + Private + Accept + Enroll + Top10perc + Top25perc + Outstate + Room.Board + PhD + Expend + Grad.Rate")
```

## Backward
```{r}
best_fit <- regsubsets(Apps ~ ., dt, nvmax = 17, method = "backward")
best_summary <- summary(best_fit)

data.table("BIC" = best_summary$bic,
           "Cp" = best_summary$cp,
           "r2" = best_summary$adjr2)[order(r2 * -1, BIC, Cp)]

par(mfrow = c(1,2))
plot(best_summary$cp, xlab = "number of features", ylab = "cp")
plot(best_fit, scale = "Cp")

par(mfrow = c(1, 2))
plot(best_summary$bic, xlab = "number of features", ylab = "bic")
plot(best_fit, scale = "bic")

backward <- as.formula("Apps ~ + Private + Accept + Enroll + Top10perc + Top25perc + Outstate + Room.Board + PhD + Expend + Grad.Rate")
```

## Conclusion
```{r}
regs <- dewey::regsearch(dt, "Apps", colnames(dt[, !c("Apps")]), 1, 10, "gaussian", 0, FALSE, TRUE)
regs

dewey <- as.formula("Apps ~ + Accept + Top10perc")
```

```{r}
# regsubsets produced the same arguments
forms <- c(normal, dewey)

lapply(forms, function(x) { summary(lm(formula = x, dt)) })
```

The model from `regsubsets` is a little bit more accurate but comes at the cost of needing to include many more variables. If data collection was no issue, the `regsubsets` one is good, if data collection is an issue, then mine is much better. Basically, as the number of applications accepted increases by one, the number of applications received increases by $1.44$. As the percent of new students that were in the top 10% of their high school class increases by one, the number of applications received increases by $35.83$.

# Problem 2
> Use the Boston data to predict the per capita crime rate using  best subset selection, forward and backward selection methods.

```{r}
dt <- data.table(ISLR2::Boston)
head(dt)
```

The `ISLR2::Boston` dataset contains "A data set containing housing values in 506 suburbs of Boston." If you want to learn more, I suggest visiting [https://rdocumentation.org/packages/ISLR2/versions/1.3-1/topics/Boston](https://rdocumentation.org/packages/ISLR2/versions/1.3-1/topics/Boston).

## Summary Stats
```{r warning=FALSE}
summary(dt)
df <- dewey::ifelsedata(data.frame(round(cor(dt), 3)), 
                        .85, "x >= y & x != 1", matchCols = FALSE)
rownames(df) <- colnames(df)
df
GGally::ggpairs(dt)
```

There's nothing crazy with these numbers. It is weird that only `tax` and `rad` are correlated above $85%$, but then again highways decrease property taxes or something. idk.

## Normal
```{r}
best_fit <- regsubsets(crim ~ ., dt, nvmax = 12)
best_summary <- summary(best_fit)

data.table("BIC" = best_summary$bic,
           "Cp" = best_summary$cp,
           "r2" = best_summary$adjr2)[order(r2 * -1, BIC, Cp)]

par(mfrow = c(1,2))
plot(best_summary$cp, xlab = "number of features", ylab = "cp")
plot(best_fit, scale = "Cp")

par(mfrow = c(1, 2))
plot(best_summary$bic, xlab = "number of features", ylab = "bic")
plot(best_fit, scale = "bic")

normal <- as.formula("crim ~ + zn + nox + dis + rad + ptratio + lstat + medv")
```

## Forward
```{r}
best_fit <- regsubsets(crim ~ ., dt, nvmax = 12, method = "forward")
best_summary <- summary(best_fit)

data.table("BIC" = best_summary$bic,
           "Cp" = best_summary$cp,
           "r2" = best_summary$adjr2)[order(r2 * -1, BIC, Cp)]

par(mfrow = c(1,2))
plot(best_summary$cp, xlab = "number of features", ylab = "cp")
plot(best_fit, scale = "Cp")

par(mfrow = c(1, 2))
plot(best_summary$bic, xlab = "number of features", ylab = "bic")
plot(best_fit, scale = "bic")

forward <- as.formula("crim ~ + zn + nox + rm + dis + rad + ptratio + lstat + medv")
```

## Backward
```{r}
best_fit <- regsubsets(crim ~ ., dt, nvmax = 12, method = "backward")
best_summary <- summary(best_fit)

data.table("BIC" = best_summary$bic,
           "Cp" = best_summary$cp,
           "r2" = best_summary$adjr2)[order(r2 * -1, BIC, Cp)]

par(mfrow = c(1,2))
plot(best_summary$cp, xlab = "number of features", ylab = "cp")
plot(best_fit, scale = "Cp")

par(mfrow = c(1, 2))
plot(best_summary$bic, xlab = "number of features", ylab = "bic")
plot(best_fit, scale = "bic")

backward <- as.formula("crim ~ zn + nox + dis + rad + ptratio + lstat + medv")
```

## Conclusion
```{r}
regs <- dewey::regsearch(dt, "crim", c(colnames(dt[, !c("crim")]), "lstat*rad"), 1, 12, "gaussian", 0, FALSE, TRUE)
regs

dewey <- as.formula("crim ~ + lstat + rad")
```

```{r}
# regsubsets produced the same arguments for normal and backward
# dropped backward
forms <- c(normal, forward, dewey)

lapply(forms, function(x) { summary(lm(formula = x, dt)) })
```

Again, `regsubsets` produces slightly better models, but mine is almost as good and is more *parsimonious*. As `lstat` increases by one, `crim` increases by $.237$ and when `rad` increases by one, `crim` increases by $.522$.
